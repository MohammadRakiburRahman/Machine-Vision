{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Machine Vision\n",
    "## Assignment 1 – Imaging\n",
    "\n",
    "## Personal details\n",
    "\n",
    "* **Name:** `Mohammad Rakibur Rahman`\n",
    "* **Student ID:** `2410695`\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment, you will read and display images in Python, use a depth map to simulate shallow depth of field (Bokeh effect), and simulate vignetting to create brightness fall-off near image edges. Please study __[`Lecture 2`](https://moodle.oulu.fi/mod/page/view.php?id=1705510)__ and the sample code in __[`Imaging.ipynb`](https://github.com/jtheikkila/mvis/blob/master/jupyter/Imaging.ipynb)__ before starting. The figure below shows the expected final outcome.\n",
    "\n",
    "<img src=\"fig1.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bb5df5dae23a69d221507d157f5c137",
     "grade": false,
     "grade_id": "cell-b2916ba27fd7a6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 1 – Read and display images (0.5 points)\n",
    "\n",
    "In this task, you will practice basic image reading and visualization. You will load a color image and a depth map, then display them side by side. The depth map was generated using __[`DepthAnything-V2`](https://github.com/DepthAnything/Depth-Anything-V2)__, a state-of-the-art monocular depth estimation method that predicts relative depth from a single image. The depth map has been manually adjusted to approximate metric depth and is stored as a 16-bit image with depth values in millimeters.\n",
    "\n",
    "### Instructions\n",
    "- **Read** `image.jpg` and `depth.png` using the OpenCV library. Use the flag `cv2.IMREAD_UNCHANGED` to properly read the 16-bit depth map.\n",
    "- **Convert** the color image from BGR to RGB as this is the order of color channels expected by Matplotlib.\n",
    "- **Display** both images side by side using Matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eb083d5a5faf7c7473928084221e56b",
     "grade": false,
     "grade_id": "cell-076450935a1ba4bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1feeb7ddc844a3af7f0798fd2f440019",
     "grade": true,
     "grade_id": "task1_code",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- YOUR CODE STARTS HERE -----------\n",
    "\n",
    "\n",
    "\n",
    "color_image = cv2.imread('D:/Class/P3/Machine Vision/A1-Imaging/image.jpg', cv2.IMREAD_COLOR)\n",
    "depth_map = cv2.imread('D:/Class/P3/Machine Vision/A1-Imaging/depth.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "color_image_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Dcolor image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(color_image_rgb)\n",
    "plt.title('Color Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# depth map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(depth_map, cmap='viridis') \n",
    "plt.title('Depth Map')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "np.save('depth_map.npy', depth_map)\n",
    "\n",
    "# ----------- YOUR CODE ENDS HERE ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6785694f55da0e846664736ec06aa3a5",
     "grade": false,
     "grade_id": "cell-d65dfde322902c09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 2 – Synthetic Bokeh (0.5 points)\n",
    "\n",
    "In this task, you will simulate a shallow depth-of-field effect, commonly referred to as the **Bokeh effect**. This effect is achieved by blurring parts of the image that are not in focus, mimicking the behavior of a lens with a wide aperture (small F-number). Smartphones typically have small sensors and large depth of field, resulting in images where both foreground and background are sharp. By artificially simulating defocus blur, we can create the Bokeh effect, selectively emphasizing the object in focus (e.g., the dog in the provided image).\n",
    "\n",
    "### Background\n",
    "The **thin-lens equation** is the foundation of defocus blur simulation:\n",
    "\n",
    "$$\\frac{1}{f} = \\frac{1}{z_o} + \\frac{1}{z_i}$$\n",
    "\n",
    "- $f$ is the focal length of the lens (in mm).\n",
    "- $z_o$ is the distance to the object being photographed (in mm).\n",
    "- $z_i$ is the distance to the image plane (in mm).\n",
    "\n",
    "Points outside the focus plane appear as small blurred circles, referred to as the circle of confusion (CoC). The size of the CoC depends on the distance of the point from the focus plane and is given by:\n",
    "$$c = D \\cdot \\frac{|z_f - z_i|}{z_i}$$\n",
    "where:\n",
    "- $D$ is the aperture diameter (in mm), calculated as $D = \\frac{f}{N}$, where $N$ is the F-number.\n",
    "- $z_f$ is the image distance for the focus plane (in mm).\n",
    "- $z_i$ is the image distance for a given depth (in mm).\n",
    "\n",
    "The size of the CoC, converted to pixels using a sensor-specific scaling factor, determines the extent of blur applied to each pixel. The scaling factor, `pixels_per_mm`, is calculated based on the physical size of the sensor (e.g., 36 mm) and the resolution of the image, linking real-world measurements to pixel dimensions.\n",
    "\n",
    "The function `defocus_blur` below (adapted from __[`Imaging.ipynb`](https://github.com/jtheikkila/mvis/blob/master/jupyter/Imaging.ipynb)__) uses this model to simulate defocus blur by applying a Gaussian blur proportional to the CoC size. While Gaussian blur is simple and efficient, a more physically accurate approach would involve using a disk-shaped kernel to mimic the shape of an aperture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "518edd3c577974751c52e9f12a1ffe3f",
     "grade": false,
     "grade_id": "cell-73207df9fe10cb7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def defocus_blur(img, depth, f, D, fdist, pixels_per_mm):\n",
    "    \"\"\"\n",
    "    Apply a synthetic defocus blur based on the thin-lens model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : Color image (H x W x 3)\n",
    "    depth : Depth map in mm (H x W)\n",
    "    f : Focal length in mm\n",
    "    D : Aperture diameter in mm\n",
    "    fdist : Focus distance (mm)\n",
    "    pixels_per_mm : Conversion factor from mm to pixels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    blurred : The blurred image\n",
    "    \"\"\"\n",
    "\n",
    "    depth = depth.astype(np.float32)\n",
    "    zf = 1.0 / (1.0/f - 1.0/fdist)  # image distance for the focus plane\n",
    "    zi = 1.0 / (1.0/f - 1.0/depth)  # image distance for each pixel\n",
    "\n",
    "    dz = np.abs(zf - zi)\n",
    "    c = D * (dz / zi)          # circle of confusion in mm\n",
    "    c *= pixels_per_mm         # convert mm -> pixels\n",
    "    c = np.clip(c, 0.0, 150.0) # limit the maximum size for safety\n",
    "\n",
    "    ci = np.linspace(c.min(), c.max(), 20)\n",
    "    dc = np.digitize(c, ci)\n",
    "    blurred = np.zeros_like(img)\n",
    "\n",
    "    for i in range(20):\n",
    "        sigma = ci[i]/2 + 0.01\n",
    "        gblur = cv2.GaussianBlur(img, (0,0), sigma)\n",
    "        mask = (dc == i+1).astype(np.uint8)\n",
    "        blurred += cv2.bitwise_and(gblur, gblur, mask=mask)\n",
    "\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0675731efdd12f06cd08b90fcc67c87d",
     "grade": false,
     "grade_id": "cell-886b122138c589c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Instructions\n",
    "- **Use** the provided `defocus_blur` function to apply synthetic Bokeh to the image.\n",
    "- **Assume** the dog is approximately 10 meters away (10 000 mm).\n",
    "- **Set** the focal length $f = 200$ mm and the F-number $N = 2.0$.\n",
    "- **Compute** `pixels_per_mm` by dividing the image width by 36 (mm). \n",
    "- **Display** the resulting image with Bokeh effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b00c2a579f8f2cd2cda7c84e5e7aca8",
     "grade": true,
     "grade_id": "task2_code",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- YOUR CODE STARTS HERE -----------\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread('D:/Class/P3/Machine Vision/A1-Imaging/image.jpg')  \n",
    "depth_map = np.load('D:/Class/P3/Machine Vision/A1-Imaging/depth_map.npy') \n",
    "\n",
    "# Parameters\n",
    "f = 200  # Focal length (mm)\n",
    "N = 2.0  # F-number\n",
    "D = f / N  # Aperture diameter (mm)\n",
    "fdist = 10000  # Focus distance (mm) \n",
    "img_width = img.shape[1]  # Image width in pixels\n",
    "pixels_per_mm = img_width / 36  # Assuming 36mm film frame\n",
    "\n",
    "# Apply defocus blur\n",
    "blurred_img = defocus_blur(img, depth_map, f, D, fdist, pixels_per_mm)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Bokeh Effect\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite('Bokeh.jpg', blurred_img)\n",
    "# ----------- YOUR CODE ENDS HERE ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e2b5c7066d28e7918a7ec2ab76ede90",
     "grade": false,
     "grade_id": "cell-e05a0909b0e3b0f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 3 – Vignetting (1.0 point)\n",
    "\n",
    "Vignetting refers to the reduction of brightness near the edges of an image, which is a common effect in photography. This phenomenon is often modeled by the cosine fourth law (refer to __[`Imaging.ipynb`](https://github.com/jtheikkila/mvis/blob/master/jupyter/Imaging.ipynb)__ for an example). However, in this task, you will create an artistic vignetting effect using an exponential falloff model:\n",
    "\n",
    "$$ I'(x, y) = I(x, y) \\times \\exp\\left(-\\frac{d^2}{\\sigma^2}\\right) $$\n",
    "\n",
    "where:\n",
    "- $I'(x, y)$: the modified pixel intensity.\n",
    "- $I(x, y)$: the original pixel intensity.\n",
    "- $d$: the distance from a pixel to the image center.\n",
    "- $\\sigma$: a parameter controlling the vignetting strength.\n",
    "\n",
    "### Instructions\n",
    "- **Set** $\\sigma = \\mathrm{width} / 2$, where $\\mathrm{width}$ is the width of the input image.\n",
    "- **Compute** the distance $d$ from each pixel to the image center (see __[`Imaging.ipynb`](https://github.com/jtheikkila/mvis/blob/master/jupyter/Imaging.ipynb)__).\n",
    "- **Apply** the exponential brightness falloff to the image from the previous task.\n",
    "- **Visualize** the final result with Bokeh and vignetting effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e73834d94d0fd8d921cee61c7b0d257",
     "grade": true,
     "grade_id": "task3_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- YOUR CODE STARTS HERE -----------\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread('D:/Class/P3/Machine Vision/A1-Imaging/Bokeh.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "sigma = img.shape[1] /2\n",
    "\n",
    "\n",
    "xi, yi = np.meshgrid(range(img.shape[1]), range(img.shape[0]))\n",
    "xi = xi.astype(np.float32) - img.shape[1] / 2\n",
    "yi = yi.astype(np.float32) - img.shape[0] / 2\n",
    "di = np.sqrt(xi**2 + yi**2)\n",
    "\n",
    "\n",
    "fp = sigma * img.shape[1] / 2  #This is the focal length in pixels\n",
    "\n",
    "\n",
    "\n",
    "falloff = np.exp(-di / (fp / 5)) \n",
    "\n",
    "\n",
    "\n",
    "falloff = np.stack([falloff, falloff, falloff], axis=2)\n",
    "\n",
    "\n",
    "\n",
    "vig = (img * falloff).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Bokeh Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vig)\n",
    "plt.title(\"Bokeh+Vignetting\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------- YOUR CODE ENDS HERE ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Aftermath\n",
    "\n",
    "Please provide short answers to the following questions:\n",
    "\n",
    "**1. How much time did you need to complete this exercise?**\n",
    "\n",
    "1 hour\n",
    "\n",
    "**2. Did you experience any issues or find anything particularly confusing?**\n",
    "\n",
    "I faced issue with reading png using np then learned to convert png to npy file .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "used code from https://github.com/jtheikkila/mvis/blob/master/jupyter/Imaging.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "613edb723ee0f29dbe95af1b8dabdaab",
     "grade": false,
     "grade_id": "cell-524d4e2be458e96f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "1. Go to `Kernel -> Restart & Clear Output` to remove all outputs.\n",
    "2. Compress this notebook (`MV_A1.ipynb`) into `MV_A1.zip`.\n",
    "3. Submit the **zip** file on Moodle.\n",
    "\n",
    "**Deadline: 19.01.2025**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
